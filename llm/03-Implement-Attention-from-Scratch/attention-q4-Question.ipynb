{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Attention from Scratch\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "Implement a **Scaled Dot-Product Attention** mechanism from scratch using PyTorch. This core component is essential in Transformer architectures and helps models focus on relevant parts of a sequence.\n",
    "\n",
    "### Background: Where Do Q, K, V Come From?\n",
    "\n",
    "In a Transformer, Q (Query), K (Key), and V (Value) are **not separate inputs**. They all come from the **same input** (the residual stream) through learned linear projections:\n",
    "\n",
    "```\n",
    "x = input tensor (batch, seq_len, d_model)  # The residual stream\n",
    "\n",
    "Q = x @ W_q  # Query projection\n",
    "K = x @ W_k  # Key projection  \n",
    "V = x @ W_v  # Value projection\n",
    "```\n",
    "\n",
    "This is called **self-attention** because the model attends to itself - the queries, keys, and values all come from the same source.\n",
    "\n",
    "### The Math\n",
    "\n",
    "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n",
    "\n",
    "### Learning Path\n",
    "\n",
    "1. **Part 1**: Core attention math (Q, K, V given) - isolate the mechanism\n",
    "2. **Part 2**: Attention mask creation (causal, padding, combined, KV cache)\n",
    "3. **Part 3**: Self-Attention class - Q, K, V from projections of single input x\n",
    "4. **Part 4**: Visualizing attention patterns\n",
    "5. **Part 5**: KV Cache for efficient inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Core Attention Math\n",
    "\n",
    "First, implement the core attention computation assuming Q, K, V are already given.\n",
    "This isolates the attention mechanism itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q shape: torch.Size([2, 8, 64])\n",
      "K shape: torch.Size([2, 8, 64])\n",
      "V shape: torch.Size([2, 8, 64])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "batch_size = 2\n",
    "seq_len = 8\n",
    "d_k = 64\n",
    "\n",
    "# For Part 1, we provide Q, K, V directly to focus on the attention math\n",
    "q = torch.randn(batch_size, seq_len, d_k)\n",
    "k = torch.randn(batch_size, seq_len, d_k)\n",
    "v = torch.randn(batch_size, seq_len, d_k)\n",
    "\n",
    "print(f\"Q shape: {q.shape}\")\n",
    "print(f\"K shape: {k.shape}\")\n",
    "print(f\"V shape: {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import einsum\n",
    "from math import inf, sqrt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def scaled_dot_product_attention(q, k, v, mask=None):\n",
    "    \"\"\"\n",
    "    Compute scaled dot-product attention.\n",
    "\n",
    "    Args:\n",
    "        q: Query tensor of shape (batch, seq_len_q, d_k)\n",
    "        k: Key tensor of shape (batch, seq_len_k, d_k)\n",
    "        v: Value tensor of shape (batch, seq_len_k, d_v)\n",
    "        mask: Optional boolean mask tensor where True indicates positions to mask out\n",
    "\n",
    "    Returns:\n",
    "        output: Attention output of shape (batch, seq_len_q, d_v)\n",
    "        attention_weights: Attention weights of shape (batch, seq_len_q, seq_len_k)\n",
    "    \"\"\"\n",
    "    d = q.shape[-1]\n",
    "    A = torch.einsum(\"bsd,btd -> bst\", [q, k])\n",
    "    A /= sqrt(d)\n",
    "    if mask is not None:\n",
    "        A = torch.masked_fill(A, mask=mask, value=-inf)\n",
    "    A = F.softmax(A, dim=-1)\n",
    "    Av = torch.einsum(\"bst,btd -> bsd\", [A, v])\n",
    "\n",
    "    return Av, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 8, 64])\n",
      "Attention weights shape: torch.Size([2, 8, 8])\n",
      "\n",
      "✓ Core attention test passed!\n"
     ]
    }
   ],
   "source": [
    "# Test against PyTorch's implementation\n",
    "output_custom, attn_weights = scaled_dot_product_attention(q, k, v)\n",
    "output_ref = F.scaled_dot_product_attention(q, k, v)\n",
    "\n",
    "print(f\"Output shape: {output_custom.shape}\")\n",
    "print(f\"Attention weights shape: {attn_weights.shape}\")\n",
    "\n",
    "assert torch.allclose(output_custom, output_ref, atol=1e-6), \"Outputs don't match!\"\n",
    "print(\"\\n\\u2713 Core attention test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Attention Mask Creation\n",
    "\n",
    "Attention masks control which positions can attend to which other positions. Two common types:\n",
    "\n",
    "1. **Causal Mask**: For autoregressive models (GPT, LLaMA), prevents attending to future tokens\n",
    "2. **Padding Mask**: For batched sequences of different lengths, prevents attending to padding tokens\n",
    "\n",
    "Mask convention: **True = masked (cannot attend), False = can attend**\n",
    "\n",
    "This matches PyTorch's `masked_fill()` behavior directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Causal Mask\n",
    "\n",
    "A causal mask prevents attention to future positions - essential for autoregressive models like GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_causal_mask(\n",
    "    seq_len_q: int, seq_len_k: int = None, device=None\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Create a causal (lower-triangular) attention mask for autoregressive models.\n",
    "\n",
    "    In autoregressive generation, each position can only attend to previous positions\n",
    "    (including itself). This prevents \"looking into the future.\"\n",
    "\n",
    "    Args:\n",
    "        seq_len_q: Query sequence length\n",
    "        seq_len_k: Key sequence length (defaults to seq_len_q)\n",
    "        device: Device to create tensor on\n",
    "\n",
    "    Returns:\n",
    "        mask: Boolean tensor of shape (seq_len_q, seq_len_k)\n",
    "              True = position should be MASKED (cannot attend)\n",
    "              False = position can be attended to\n",
    "\n",
    "    Example for seq_len=4:\n",
    "        Q\\\\K   0      1      2      3\n",
    "        0   [False, True,  True,  True ]   # Query 0 attends only to Key 0\n",
    "        1   [False, False, True,  True ]   # Query 1 attends to Keys 0-1\n",
    "        2   [False, False, False, True ]   # Query 2 attends to Keys 0-2\n",
    "        3   [False, False, False, False]   # Query 3 attends to Keys 0-3\n",
    "    \"\"\"\n",
    "    if seq_len_k is None:\n",
    "        seq_len_k = seq_len_q\n",
    "    mask = torch.ones((seq_len_q, seq_len_k))\n",
    "    mask = torch.triu(mask, diagonal=1).to(bool)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Causal mask (4x4):\n",
      "tensor([[False,  True,  True,  True],\n",
      "        [False, False,  True,  True],\n",
      "        [False, False, False,  True],\n",
      "        [False, False, False, False]])\n",
      "\n",
      "True = masked (cannot attend), False = can attend\n",
      "\n",
      "Asymmetric mask (2 queries, 4 keys):\n",
      "tensor([[False,  True,  True,  True],\n",
      "        [False, False,  True,  True]])\n",
      "\n",
      "✓ Causal mask test passed!\n"
     ]
    }
   ],
   "source": [
    "# Test causal mask creation\n",
    "mask = create_causal_mask(4)\n",
    "print(\"Causal mask (4x4):\")\n",
    "print(mask)\n",
    "print(\"\\nTrue = masked (cannot attend), False = can attend\")\n",
    "\n",
    "# Verify properties\n",
    "assert mask.shape == (4, 4)\n",
    "assert mask[0, 0] == False, \"Position (0,0) should NOT be masked (can attend to self)\"\n",
    "assert mask[0, 1] == True, \"Position (0,1) should be masked (cannot attend to future)\"\n",
    "assert mask[3, 0] == False, \"Position (3,0) should NOT be masked (can attend to past)\"\n",
    "assert mask.sum() == 6, \"Upper triangle should have 6 masked elements\"\n",
    "\n",
    "# Test with different Q/K lengths\n",
    "mask_asymm = create_causal_mask(2, 4)\n",
    "print(f\"\\nAsymmetric mask (2 queries, 4 keys):\")\n",
    "print(mask_asymm)\n",
    "assert mask_asymm.shape == (2, 4)\n",
    "\n",
    "print(\"\\n\\u2713 Causal mask test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Padding Mask\n",
    "\n",
    "When batching sequences of different lengths, shorter sequences are padded. The padding tokens should not be attended to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(lengths: torch.Tensor, max_len: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Create a padding mask for variable-length sequences in a batch.\n",
    "\n",
    "    When batching sequences of different lengths, shorter sequences are padded.\n",
    "    The padding tokens should not be attended to.\n",
    "\n",
    "    Args:\n",
    "        lengths: Tensor of shape (batch_size,) containing actual sequence lengths\n",
    "        max_len: Maximum sequence length (padded length)\n",
    "\n",
    "    Returns:\n",
    "        mask: Boolean tensor of shape (batch_size, max_len)\n",
    "              True = padding position (should be MASKED)\n",
    "              False = real token (can be attended to)\n",
    "\n",
    "    Example:\n",
    "        lengths = [3, 5, 2], max_len = 5\n",
    "\n",
    "        Returns:\n",
    "        [[False, False, False, True,  True ],   # seq 0: tokens 0-2 real, 3-4 padding\n",
    "         [False, False, False, False, False],   # seq 1: all 5 tokens real\n",
    "         [False, False, True,  True,  True ]]   # seq 2: tokens 0-1 real, 2-4 padding\n",
    "    \"\"\"\n",
    "    return (\n",
    "        torch.arange(max_len)[None, :] >= lengths[:, None]\n",
    "    )  # (1, m) >= (b, 1) -> ([[0,1,...max_len],...[0,1,...max_len]])>=([[a,b,...,m],[c,d,...,n]]) -> (b, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  True,  True],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False,  True,  True,  True]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = torch.tensor([3, 5, 2])\n",
    "max_len = 5\n",
    "torch.arange(max_len)[None, :] >= lengths[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding mask (batch=3, max_len=5):\n",
      "Sequence lengths: [3, 5, 2]\n",
      "tensor([[False, False, False,  True,  True],\n",
      "        [False, False, False, False, False],\n",
      "        [False, False,  True,  True,  True]])\n",
      "\n",
      "✓ Padding mask test passed!\n"
     ]
    }
   ],
   "source": [
    "# Test padding mask creation\n",
    "lengths = torch.tensor([3, 5, 2])\n",
    "mask = create_padding_mask(lengths, max_len=5)\n",
    "print(\"Padding mask (batch=3, max_len=5):\")\n",
    "print(f\"Sequence lengths: {lengths.tolist()}\")\n",
    "print(mask)\n",
    "\n",
    "# Verify\n",
    "assert mask.shape == (3, 5)\n",
    "assert mask[0].tolist() == [False, False, False, True, True]\n",
    "assert mask[1].tolist() == [False, False, False, False, False]\n",
    "assert mask[2].tolist() == [False, False, True, True, True]\n",
    "\n",
    "print(\"\\n\\u2713 Padding mask test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Combined Attention Mask\n",
    "\n",
    "In practice, you often need both causal masking AND padding masking together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def create_attention_mask(\n",
    "    seq_len_q: int,\n",
    "    seq_len_k: int = None,\n",
    "    is_causal: bool = True,\n",
    "    key_padding_lengths: torch.Tensor = None,\n",
    "    device=None,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Create a combined attention mask handling both causality and padding.\n",
    "\n",
    "    Args:\n",
    "        seq_len_q: Query sequence length\n",
    "        seq_len_k: Key sequence length\n",
    "        is_causal: Whether to apply causal masking\n",
    "        key_padding_lengths: If provided, actual lengths of key sequences (batch_size,)\n",
    "        device: Device to create tensor on\n",
    "\n",
    "    Returns:\n",
    "        mask: Boolean tensor, True = masked position\n",
    "              Shape: (seq_len_q, seq_len_k) if no padding\n",
    "              Shape: (batch_size, seq_len_q, seq_len_k) if padding provided\n",
    "    \"\"\"\n",
    "    # causal mask\n",
    "    if seq_len_k is None:\n",
    "        seq_len_k = seq_len_q\n",
    "    mask = torch.ones((seq_len_q, seq_len_k), dtype=torch.bool, device=device)\n",
    "    if not is_causal and key_padding_lengths is None:\n",
    "        return mask\n",
    "    mask = torch.triu(mask, diagonal=1)\n",
    "    if is_causal and key_padding_lengths is None:\n",
    "        return mask\n",
    "\n",
    "    # padding mask\n",
    "    max_len = seq_len_k\n",
    "    padding_mask = (\n",
    "        torch.arange(max_len, device=device)[None, :] >= key_padding_lengths[:, None]\n",
    "    )  # (batch_size, max_len)\n",
    "    if not is_causal:\n",
    "        return padding_mask.to(device)\n",
    "\n",
    "    # make out, a (batch_size, seq_len_q, max_len) tensor.\n",
    "    # only the first key_padding_lengths[i] columns should be unmasked for out[i, ...]\n",
    "    out = padding_mask[:, None, :] | mask[None, :, :]\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Causal-only mask:\n",
      "tensor([[False,  True,  True,  True],\n",
      "        [False, False,  True,  True],\n",
      "        [False, False, False,  True],\n",
      "        [False, False, False, False]])\n",
      "\n",
      "Combined causal + padding mask (batch=2):\n",
      "Key lengths: [4, 3]\n",
      "Batch 0 (full length):\n",
      "tensor([[False,  True,  True,  True],\n",
      "        [False, False,  True,  True],\n",
      "        [False, False, False,  True],\n",
      "        [False, False, False, False]])\n",
      "Batch 1 (length=3, position 3 is padding):\n",
      "tensor([[False,  True,  True,  True],\n",
      "        [False, False,  True,  True],\n",
      "        [False, False, False,  True],\n",
      "        [False, False, False,  True]])\n",
      "\n",
      "✓ Combined mask test passed!\n"
     ]
    }
   ],
   "source": [
    "# Test combined mask: causal only\n",
    "mask_causal = create_attention_mask(4, is_causal=True)\n",
    "print(\"Causal-only mask:\")\n",
    "print(mask_causal)\n",
    "\n",
    "# Test combined mask: causal + padding\n",
    "lengths = torch.tensor([4, 3])  # batch of 2, one full, one with padding\n",
    "mask_combined = create_attention_mask(4, is_causal=True, key_padding_lengths=lengths)\n",
    "print(f\"\\nCombined causal + padding mask (batch=2):\")\n",
    "print(f\"Key lengths: {lengths.tolist()}\")\n",
    "print(f\"Batch 0 (full length):\")\n",
    "print(mask_combined[0])\n",
    "print(f\"Batch 1 (length=3, position 3 is padding):\")\n",
    "print(mask_combined[1])\n",
    "\n",
    "# Verify batch 1 has position 3 masked for all queries\n",
    "assert mask_combined[1, :, 3].all(), \"Padding position should be masked for all queries\"\n",
    "\n",
    "print(\"\\n\\u2713 Combined mask test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d. Causal Mask with KV Cache\n",
    "\n",
    "During autoregressive generation with KV cache, the mask needs special handling:\n",
    "- New queries can attend to ALL cached positions (they're in the past)\n",
    "- Causal masking only applies within the new tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def create_causal_mask_with_cache(\n",
    "    seq_len_q: int, seq_len_k: int, cache_len: int, device=None\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Create a causal mask for attention with KV cache.\n",
    "\n",
    "    During autoregressive generation with KV cache:\n",
    "    - Query has only new tokens (usually 1 during generation)\n",
    "    - Keys include cached tokens + new tokens\n",
    "    - New queries can attend to ALL cached keys (they're in the past)\n",
    "\n",
    "    Args:\n",
    "        seq_len_q: Number of new query tokens (typically 1 during generation)\n",
    "        seq_len_k: Total key length (cache_len + seq_len_q)\n",
    "        cache_len: Number of cached tokens\n",
    "        device: Device to create tensor on\n",
    "\n",
    "    Returns:\n",
    "        mask: Boolean tensor of shape (seq_len_q, seq_len_k)\n",
    "\n",
    "    Example: cache_len=3, seq_len_q=2, seq_len_k=5\n",
    "        Keys:    [cached0, cached1, cached2, new0, new1]\n",
    "\n",
    "        Q\\\\K      c0     c1     c2    new0   new1\n",
    "        new0  [False, False, False, False, True ]  # new0 attends to cache + itself\n",
    "        new1  [False, False, False, False, False]  # new1 attends to cache + new0 + itself\n",
    "    \"\"\"\n",
    "    mask = torch.ones((seq_len_q, seq_len_k), device=device)\n",
    "    diagonal = (\n",
    "        cache_len + 1\n",
    "    )  # dont mask any of the cache, don't mask token attn to itself\n",
    "    mask = torch.triu(mask, diagonal=diagonal).to(dtype=torch.bool)\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KV cache mask (1 new token, 4 cached):\n",
      "Shape: torch.Size([1, 5])\n",
      "tensor([[False, False, False, False, False]])\n",
      "\n",
      "KV cache mask (3 new tokens, 3 cached):\n",
      "Keys: [cached0, cached1, cached2, new0, new1, new2]\n",
      "tensor([[False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False,  True],\n",
      "        [False, False, False, False, False, False]])\n",
      "\n",
      "Prefill mask (3 tokens, no cache):\n",
      "tensor([[False,  True,  True],\n",
      "        [False, False,  True],\n",
      "        [False, False, False]])\n",
      "\n",
      "✓ KV cache mask test passed!\n"
     ]
    }
   ],
   "source": [
    "# Test KV cache mask: single token generation (most common case)\n",
    "mask_single = create_causal_mask_with_cache(seq_len_q=1, seq_len_k=5, cache_len=4)\n",
    "print(\"KV cache mask (1 new token, 4 cached):\")\n",
    "print(f\"Shape: {mask_single.shape}\")\n",
    "print(mask_single)\n",
    "assert mask_single[0].tolist() == [False, False, False, False, False], (\n",
    "    \"Single new token can attend to all\"\n",
    ")\n",
    "\n",
    "# Test KV cache mask: multi-token (prefill or speculative decoding)\n",
    "mask_multi = create_causal_mask_with_cache(seq_len_q=3, seq_len_k=6, cache_len=3)\n",
    "print(\"\\nKV cache mask (3 new tokens, 3 cached):\")\n",
    "print(f\"Keys: [cached0, cached1, cached2, new0, new1, new2]\")\n",
    "print(mask_multi)\n",
    "# new0 can attend to cache + itself\n",
    "assert mask_multi[0].tolist() == [False, False, False, False, True, True]\n",
    "# new2 can attend to everything\n",
    "assert mask_multi[2].tolist() == [False, False, False, False, False, False]\n",
    "\n",
    "# Test prefill (no cache)\n",
    "mask_prefill = create_causal_mask_with_cache(seq_len_q=3, seq_len_k=3, cache_len=0)\n",
    "print(\"\\nPrefill mask (3 tokens, no cache):\")\n",
    "print(mask_prefill)\n",
    "assert mask_prefill[0, 1] == True, \"First query can't see second\"\n",
    "assert mask_prefill[2, 0] == False, \"Third query can see first\"\n",
    "\n",
    "print(\"\\n\\u2713 KV cache mask test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Masks with Attention\n",
    "\n",
    "Now let's verify our masks work correctly with the attention function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Causal attention test passed!\n",
      "\n",
      "Attention weights (notice upper triangle is 0):\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3300, 0.6700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1000, 0.4300, 0.4700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1200, 0.0600, 0.0100, 0.8100, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0400, 0.0100, 0.0400, 0.8300, 0.0900, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0800, 0.0500, 0.1000, 0.5000, 0.2300, 0.0400, 0.0000, 0.0000],\n",
      "        [0.0200, 0.1200, 0.3800, 0.2500, 0.0500, 0.1600, 0.0200, 0.0000],\n",
      "        [0.1400, 0.0300, 0.0800, 0.0200, 0.0600, 0.4000, 0.0800, 0.1900]])\n"
     ]
    }
   ],
   "source": [
    "# Test causal mask with attention\n",
    "torch.manual_seed(42)\n",
    "q_test = torch.randn(batch_size, seq_len, d_k)\n",
    "k_test = torch.randn(batch_size, seq_len, d_k)\n",
    "v_test = torch.randn(batch_size, seq_len, d_k)\n",
    "\n",
    "causal_mask = create_causal_mask(seq_len)\n",
    "output_masked, attn_weights_masked = scaled_dot_product_attention(\n",
    "    q_test, k_test, v_test, mask=causal_mask\n",
    ")\n",
    "\n",
    "# Verify upper triangle is zero (no attention to future tokens)\n",
    "upper_triangle = attn_weights_masked[0].triu(diagonal=1)\n",
    "assert torch.allclose(upper_triangle, torch.zeros_like(upper_triangle), atol=1e-6), (\n",
    "    \"Causal mask failed! Positions are attending to future tokens.\"\n",
    ")\n",
    "\n",
    "# Verify each row sums to 1\n",
    "row_sums = attn_weights_masked.sum(dim=-1)\n",
    "assert torch.allclose(row_sums, torch.ones_like(row_sums), atol=1e-6), (\n",
    "    \"Attention weights don't sum to 1!\"\n",
    ")\n",
    "\n",
    "# Compare against PyTorch's is_causal\n",
    "output_ref = F.scaled_dot_product_attention(q_test, k_test, v_test, is_causal=True)\n",
    "assert torch.allclose(output_masked, output_ref, atol=1e-6), (\n",
    "    \"Doesn't match PyTorch is_causal!\"\n",
    ")\n",
    "\n",
    "print(\"\\u2713 Causal attention test passed!\")\n",
    "print(\"\\nAttention weights (notice upper triangle is 0):\")\n",
    "print(attn_weights_masked[0].round(decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Self-Attention with Projections\n",
    "\n",
    "Now implement **actual self-attention** where Q, K, V come from learned projections of a single input x.\n",
    "\n",
    "This is how attention works in real Transformers:\n",
    "- Input: `x` (batch, seq_len, d_model) - the residual stream\n",
    "- Q, K, V are computed as `x @ W_q`, `x @ W_k`, `x @ W_v`\n",
    "- Output projection: `attention_output @ W_o`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from math import sqrt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Self-Attention layer where Q, K, V come from projections of the same input.\n",
    "\n",
    "    This is how attention actually works in Transformers - the input x\n",
    "    (the residual stream) is projected to create Q, K, and V.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model: int):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.QKV = nn.Linear(d_model, 3 * d_model, bias=False)\n",
    "        self.out_proj = nn.Linear(d_model, d_model, bias=False)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        is_causal: bool = False,\n",
    "        key_padding_lengths: torch.Tensor = None,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor (batch, seq_len, d_model) - the residual stream\n",
    "            is_causal: Whether to apply causal masking\n",
    "            key_padding_lengths: If provided, actual lengths for padding mask\n",
    "\n",
    "        Returns:\n",
    "            output: Self-attention output (batch, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        qkv: torch.Tensor = self.QKV(x)  # (batch, seq_len, 3*d_model)\n",
    "        q, k, v = qkv.chunk(3, dim=-1)  # 3 x (batch, seq_len, d_model)\n",
    "        b, s, d = q.shape\n",
    "        t = k.shape[1]\n",
    "\n",
    "        # self-attention matrix\n",
    "        a = torch.einsum(\"bsd, btd -> bst\", [q, k]) / sqrt(self.d_model)\n",
    "        if is_causal:  # make causal mask\n",
    "            mask = torch.triu(torch.ones_like(a), diagonal=1).to(torch.bool)\n",
    "            a = torch.masked_fill(a, mask, float(\"-inf\"))\n",
    "        if key_padding_lengths is not None:\n",
    "            # build mask of key padding lengths for every batch\n",
    "            assert len(key_padding_lengths) == b\n",
    "            max_len = t\n",
    "            padding_mask = (\n",
    "                key_padding_lengths[:, None]\n",
    "                <= torch.arange(max_len, device=x.device)[None, :]\n",
    "            )  # (b, 1) > (1, t): (b, t)\n",
    "            padding_mask = padding_mask[:, None, :]  # (b, 1, t)\n",
    "            a = a.masked_fill(padding_mask, float(\"-inf\"))\n",
    "\n",
    "        a = F.softmax(a, dim=-1)\n",
    "        av = torch.einsum(\"bst, btd -> bsd\", [a, v])\n",
    "        return self.out_proj(av)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([2, 8, 64])\n",
      "This single input x will be projected to create Q, K, and V\n",
      "\n",
      "Output shape: torch.Size([2, 8, 64])\n",
      "Causal output shape: torch.Size([2, 8, 64])\n",
      "Padded output shape: torch.Size([2, 8, 64])\n",
      "\n",
      "✓ Self-Attention test passed!\n"
     ]
    }
   ],
   "source": [
    "# Test Self-Attention\n",
    "torch.manual_seed(42)\n",
    "\n",
    "batch_size = 2\n",
    "seq_len = 8\n",
    "d_model = 64\n",
    "\n",
    "# Single input - the residual stream\n",
    "x = torch.randn(batch_size, seq_len, d_model)\n",
    "print(f\"Input x shape: {x.shape}\")\n",
    "print(\"This single input x will be projected to create Q, K, and V\")\n",
    "\n",
    "# Create self-attention layer\n",
    "self_attn = SelfAttention(d_model)\n",
    "\n",
    "# Forward pass (bidirectional)\n",
    "output = self_attn(x)\n",
    "print(f\"\\nOutput shape: {output.shape}\")\n",
    "assert output.shape == x.shape, \"Output shape should match input shape!\"\n",
    "\n",
    "# Forward pass (causal)\n",
    "output_causal = self_attn(x, is_causal=True)\n",
    "print(f\"Causal output shape: {output_causal.shape}\")\n",
    "\n",
    "# Forward pass (with padding)\n",
    "lengths = torch.tensor([8, 5])  # second sequence is shorter\n",
    "output_padded = self_attn(x, is_causal=True, key_padding_lengths=lengths)\n",
    "print(f\"Padded output shape: {output_padded.shape}\")\n",
    "\n",
    "print(\"\\n\\u2713 Self-Attention test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing Attention Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice how causal attention has zeros in the upper triangle -\n",
      "each position can only attend to itself and earlier positions.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get attention weights for both bidirectional and causal attention\n",
    "_, attn_bidirectional = scaled_dot_product_attention(q_test, k_test, v_test, mask=None)\n",
    "_, attn_causal = scaled_dot_product_attention(\n",
    "    q_test, k_test, v_test, mask=create_causal_mask(seq_len)\n",
    ")\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "im1 = axes[0].imshow(\n",
    "    attn_bidirectional[0].detach().numpy(), cmap=\"Blues\", vmin=0, vmax=0.5\n",
    ")\n",
    "axes[0].set_title(\"Bidirectional Attention\", fontsize=12)\n",
    "axes[0].set_xlabel(\"Key Position\")\n",
    "axes[0].set_ylabel(\"Query Position\")\n",
    "plt.colorbar(im1, ax=axes[0], shrink=0.8)\n",
    "\n",
    "im2 = axes[1].imshow(attn_causal[0].detach().numpy(), cmap=\"Blues\", vmin=0, vmax=0.5)\n",
    "axes[1].set_title(\"Causal Attention (Autoregressive)\", fontsize=12)\n",
    "axes[1].set_xlabel(\"Key Position\")\n",
    "axes[1].set_ylabel(\"Query Position\")\n",
    "plt.colorbar(im2, ax=axes[1], shrink=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"attention_patterns.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice how causal attention has zeros in the upper triangle -\")\n",
    "print(\"each position can only attend to itself and earlier positions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Self-Attention with KV Cache\n",
    "\n",
    "### Why KV Cache?\n",
    "\n",
    "During autoregressive generation:\n",
    "- Without cache: Recompute K, V for ALL tokens at every step → O(n²)\n",
    "- With cache: Only compute K, V for NEW token, concatenate with cache → O(n)\n",
    "\n",
    "### Key Insight\n",
    "\n",
    "We cache the **projected** K and V values (after `W_k(x)` and `W_v(x)`).\n",
    "For each new token, we:\n",
    "1. Compute Q, K, V from the new token's x\n",
    "2. Concatenate new K, V with cached K, V\n",
    "3. Compute attention using full K, V but only new Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionWithCache(nn.Module):\n",
    "    \"\"\"\n",
    "    Self-Attention with KV Cache for efficient autoregressive generation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model: int):\n",
    "        super().__init__()\n",
    "        pass\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        cache_k: torch.Tensor = None,\n",
    "        cache_v: torch.Tensor = None,\n",
    "        is_causal: bool = True,\n",
    "    ) -> tuple:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor (batch, seq_len, d_model)\n",
    "            cache_k: Cached keys (batch, cached_len, d_model) or None\n",
    "            cache_v: Cached values (batch, cached_len, d_model) or None\n",
    "            is_causal: Whether to apply causal masking (default True for autoregressive)\n",
    "\n",
    "        Returns:\n",
    "            output: Attention output (batch, seq_len, d_model)\n",
    "            new_cache_k: Updated key cache\n",
    "            new_cache_v: Updated value cache\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Self-Attention with KV Cache\n",
    "print(\"=== Testing Self-Attention with KV Cache ===\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "batch_size = 2\n",
    "d_model = 64\n",
    "\n",
    "self_attn_cached = SelfAttentionWithCache(d_model)\n",
    "\n",
    "# Step 1: Process prompt (3 tokens) - prefill\n",
    "prompt = torch.randn(batch_size, 3, d_model)\n",
    "print(f\"\\nInput prompt shape: {prompt.shape}\")\n",
    "print(\"Q, K, V will all be computed from this single input via learned projections\")\n",
    "\n",
    "out1, cache_k, cache_v = self_attn_cached(prompt, None, None)\n",
    "print(f\"\\nAfter prompt: cache shape = {cache_k.shape}\")\n",
    "\n",
    "# Step 2: Generate token 4 (single new token)\n",
    "new_token = torch.randn(batch_size, 1, d_model)\n",
    "out2, cache_k, cache_v = self_attn_cached(new_token, cache_k, cache_v)\n",
    "print(f\"After token 4: cache shape = {cache_k.shape}\")\n",
    "\n",
    "# Step 3: Generate token 5\n",
    "new_token = torch.randn(batch_size, 1, d_model)\n",
    "out3, cache_k, cache_v = self_attn_cached(new_token, cache_k, cache_v)\n",
    "print(f\"After token 5: cache shape = {cache_k.shape}\")\n",
    "\n",
    "# Verify\n",
    "assert cache_k.shape == (batch_size, 5, d_model)\n",
    "assert out3.shape == (batch_size, 1, d_model)\n",
    "\n",
    "print(\"\\n\\u2713 Self-Attention with KV Cache test passed!\")\n",
    "print(\"\\nKey insight: Each generation step only computes K, V for 1 new token,\")\n",
    "print(\"but attends over ALL previous tokens via the cache.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interview Tips\n",
    "\n",
    "**Q: Where do Q, K, V come from in self-attention?**\n",
    "A: All three come from learned linear projections of the same input x (the residual stream): Q = W_q(x), K = W_k(x), V = W_v(x).\n",
    "\n",
    "**Q: What's the difference between self-attention and cross-attention?**\n",
    "A: In self-attention, Q, K, V come from the same input. In cross-attention (like encoder-decoder), Q comes from one source (decoder) while K, V come from another (encoder output).\n",
    "\n",
    "**Q: Why scale by sqrt(d_k)?**\n",
    "A: To prevent dot products from growing too large with high dimensions, which would push softmax into regions with tiny gradients.\n",
    "\n",
    "**Q: How do you create a causal mask?**\n",
    "A: Use `torch.triu(..., diagonal=1)` to create a boolean upper triangular matrix where True = masked. The upper triangle blocks attention to future positions.\n",
    "\n",
    "**Q: How do you handle padding in attention?**\n",
    "A: Create a padding mask where positions >= sequence length are True (masked). Combine with causal mask using OR operation.\n",
    "\n",
    "**Q: What is KV cache and why is it used?**\n",
    "A: KV cache stores computed K, V from previous tokens during autoregressive generation. Without it, generating n tokens requires O(n²) computations; with it, only O(n).\n",
    "\n",
    "**Q: How does masking work with KV cache?**\n",
    "A: New queries can attend to all cached positions (they're in the past). Causal masking only applies within the new tokens. Use `create_causal_mask_with_cache()` with the cache length offset.\n",
    "\n",
    "**Q: What happens during prefill vs decode phases?**\n",
    "A: \n",
    "- Prefill: Process entire prompt at once, populate cache (compute-bound)\n",
    "- Decode: Generate one token at a time using cache (memory-bound)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
