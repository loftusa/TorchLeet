{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "217b1f70",
   "metadata": {},
   "source": [
    "# Implement RMS Normalization\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "**Root Mean Square Layer Normalization (RMSNorm)** is a simplification of Layer Normalization that has become the standard in modern LLMs like LLaMA, Mistral, and Gemma. Your task is to implement RMSNorm from scratch using PyTorch.\n",
    "\n",
    "---\n",
    "\n",
    "### Background\n",
    "\n",
    "Unlike LayerNorm, RMSNorm **does not center the inputs** (no mean subtraction). It only normalizes by the root mean square, making it computationally cheaper while maintaining similar performance.\n",
    "\n",
    "#### Mathematical Formula\n",
    "\n",
    "For an input vector $x \\in \\mathbb{R}^d$:\n",
    "\n",
    "$$\n",
    "\\text{RMSNorm}(x) = \\frac{x}{\\text{RMS}(x)} \\cdot \\gamma\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\text{RMS}(x) = \\sqrt{\\frac{1}{d} \\sum_{i=1}^{d} x_i^2 + \\epsilon}$\n",
    "- $\\gamma$ is a learnable scale parameter (initialized to ones)\n",
    "- $\\epsilon$ is a small constant for numerical stability\n",
    "\n",
    "#### Why RMSNorm?\n",
    "\n",
    "1. **Faster**: No mean computation required\n",
    "2. **Simpler**: Fewer operations than LayerNorm\n",
    "3. **Effective**: Empirically works just as well for LLMs\n",
    "\n",
    "---\n",
    "\n",
    "### Requirements\n",
    "\n",
    "1. **Define an `RMSNorm` class** that:\n",
    "   - Inherits from `nn.Module`\n",
    "   - Has a learnable scale parameter `gamma` of shape `(dim,)`\n",
    "   - Applies RMS normalization along the last dimension\n",
    "\n",
    "2. **Handle arbitrary batch dimensions**:\n",
    "   - Input shape: `(..., dim)` where `...` represents any number of batch dimensions\n",
    "   - Output shape: same as input\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5692f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-8):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.scale = nn.Parameter(torch.ones(dim))  # gamma\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: shape (..., dim)\n",
    "        norm = torch.sqrt(x.pow(2).mean(dim=-1, keepdim=True) + self.eps)  # RMS\n",
    "        return (x / norm) * self.scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5813413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 5)  # e.g., (batch_size=3, features=5)\n",
    "rmsnorm = RMSNorm(dim=5)\n",
    "out = rmsnorm(x)\n",
    "print(out.shape)  # should be (3, 5)\n",
    "assert out.shape == (3, 5), \"Output shape mismatch\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
