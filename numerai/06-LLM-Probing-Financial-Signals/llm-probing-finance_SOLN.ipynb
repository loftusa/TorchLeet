{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# LLM Probing for Financial Signals\n\n## Context\nThis is my most unique angle for Numerai. My PhD research focuses on mechanistic interpretability — understanding what information is encoded inside LLM representations. My ICLR 2025 paper (NNsight/NDIF) built infrastructure for probing LLM internals at scale.\n\n**Key insight**: Before investing compute in fine-tuning an LLM on financial text, we should first *probe* the model to understand what financial knowledge already exists in its representations, and at which layers.\n\n## Pipeline\nFinancial text → nnterp tracing → Extract hidden states per layer → Train linear probes → Identify which layers encode financial signals\n\n**This notebook uses nnterp** (standardized wrapper around nnsight, my own tool) for clean hidden state extraction.\n\n## Why This Matters for Numerai\n- Different layers encode different information: early layers capture syntax, middle layers capture semantics, late layers capture task-specific features\n- By probing, we can select the BEST layer for feature extraction — not just use the last layer\n- This is a principled approach to \"which representation should I use?\" — a question most practitioners answer by guessing\n\n## My Background\n- **NNsight & NDIF** (ICLR 2025): Open-source suite for probing & manipulating LLM weights. Ray GCS backend with AWS object storage and VLLM.\n- **Token Entanglement** (NeurIPS MechInterp 2025): Investigation of how information flows between tokens in LLMs\n- **PhD Advisor**: David Bau (pioneer of network dissection and representation engineering)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom nnterp import StandardizedTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import StandardScaler"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load a Small Language Model\n",
    "We use Gemma-3-270M-IT (270M params, 18 transformer layers, 2048 hidden dim) for demonstration. In production, you'd probe larger models (Llama-3, Mistral) or financial-specific models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "model_name = \"google/gemma-3-270m-it\"\nmodel = StandardizedTransformer(model_name, device_map=\"auto\", dispatch=True)\n\nn_layers = model.config.num_hidden_layers\nhidden_dim = model.config.hidden_size\nprint(f\"Model: {model_name}\")\nprint(f\"Layers: {n_layers}, Hidden dim: {hidden_dim}\")\nprint(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Financial Text Dataset with Labels\n",
    "We create headlines labeled with return direction (up/down). The question: does Gemma-3 encode return-relevant information, and at which layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Financial headlines with binary return labels\n",
    "# In production: real headlines + real returns\n",
    "data = [\n",
    "    # Positive returns (label=1)\n",
    "    (\"Apple reports record quarterly revenue exceeding all analyst estimates\", 1),\n",
    "    (\"NVIDIA data center revenue surges 400% on AI chip demand\", 1),\n",
    "    (\"Microsoft Azure growth re-accelerates beating expectations\", 1),\n",
    "    (\"Company announces massive share buyback program boosting stock\", 1),\n",
    "    (\"Strong jobs report signals robust economic growth ahead\", 1),\n",
    "    (\"Tech giant beats earnings estimates by wide margin\", 1),\n",
    "    (\"Breakthrough drug receives FDA approval for rare disease\", 1),\n",
    "    (\"Major acquisition deal completed at premium valuation\", 1),\n",
    "    (\"Company raises full-year guidance citing strong demand\", 1),\n",
    "    (\"Revenue growth accelerates driven by new product launch\", 1),\n",
    "    (\"Profit margins expand as cost cutting measures take effect\", 1),\n",
    "    (\"Company wins billion dollar government defense contract\", 1),\n",
    "    (\"Subscriber growth exceeds expectations in latest quarter\", 1),\n",
    "    (\"New partnership with industry leader boosts outlook\", 1),\n",
    "    (\"Company achieves profitability ahead of schedule\", 1),\n",
    "    (\"Strong holiday sales drive record fourth quarter results\", 1),\n",
    "    (\"Analyst upgrades stock citing improved business fundamentals\", 1),\n",
    "    (\"Company expands market share in key growth segment\", 1),\n",
    "    (\"Cash flow reaches record high enabling increased dividends\", 1),\n",
    "    (\"Patent portfolio expansion strengthens competitive position\", 1),\n",
    "    # Negative returns (label=0)\n",
    "    (\"Company misses revenue expectations amid weakening demand\", 0),\n",
    "    (\"Tesla recalls 2 million vehicles over safety concerns\", 0),\n",
    "    (\"Major data breach exposes millions of customer records\", 0),\n",
    "    (\"Company announces significant workforce reduction layoffs\", 0),\n",
    "    (\"Regulatory investigation launched into business practices\", 0),\n",
    "    (\"Supply chain disruptions force production shutdown\", 0),\n",
    "    (\"Product recall due to safety defects affects millions\", 0),\n",
    "    (\"Company warns of lower guidance citing headwinds\", 0),\n",
    "    (\"Unexpected quarterly loss shocks Wall Street analysts\", 0),\n",
    "    (\"Key executive departure raises governance concerns\", 0),\n",
    "    (\"Antitrust lawsuit threatens core business model\", 0),\n",
    "    (\"Credit rating downgrade increases borrowing costs\", 0),\n",
    "    (\"Market share losses accelerate in competitive landscape\", 0),\n",
    "    (\"Accounting irregularities discovered during audit review\", 0),\n",
    "    (\"Failed clinical trial sends biotech shares plummeting\", 0),\n",
    "    (\"Trade restrictions limit access to key international market\", 0),\n",
    "    (\"Debt levels raise concerns about financial sustainability\", 0),\n",
    "    (\"Customer churn rate increases in latest reporting period\", 0),\n",
    "    (\"Class action lawsuit filed against company by shareholders\", 0),\n",
    "    (\"Competitor launches superior product at lower price point\", 0),\n",
    "]\n",
    "\n",
    "texts = [t for t, _ in data]\n",
    "labels = np.array([l for _, l in data])\n",
    "print(f\"Dataset: {len(texts)} headlines ({labels.sum()} positive, {len(labels) - labels.sum()} negative)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Extract Hidden States at Every Layer\n\nThis is the core of probing. We use **nnterp** (a standardized wrapper around nnsight, my ICLR 2025 paper) to cleanly extract hidden states from every transformer layer. The key advantage: `model.layers_output[i]` works identically across all HuggingFace architectures — no need to know the model-specific module names.\n\nWe use the last token's representation (standard for causal LMs with left-to-right attention)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def extract_hidden_states(texts, model, n_layers):\n    \"\"\"Extract hidden states from every transformer layer using nnterp.\n\n    Uses nnterp's standardized layer access (model.layers_output[i]) for clean extraction.\n    Returns: dict mapping layer_idx -> np.array of shape (n_texts, hidden_dim)\n    \"\"\"\n    all_hidden = {l: [] for l in range(n_layers)}\n\n    for text in texts:\n        with model.trace(text):\n            # Each transformer layer output (last token = causal LM standard)\n            layer_outs = []\n            for i in range(n_layers):\n                h = model.layers_output[i][:, -1, :].save()\n                layer_outs.append(h)\n\n        for i in range(n_layers):\n            all_hidden[i].append(layer_outs[i].value.detach().cpu().float().numpy().squeeze())\n\n    return {l: np.stack(v) for l, v in all_hidden.items()}\n\n# Extract hidden states from all layers\nprint(f\"Extracting hidden states from {n_layers} transformer layers using nnterp...\")\nhidden_states = extract_hidden_states(texts, model, n_layers)\nprint(f\"Done! Shape per layer: {hidden_states[0].shape}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Linear Probes Per Layer\n",
    "\n",
    "A linear probe is a simple logistic regression trained on the hidden states to predict the label. If a layer's probe has high accuracy, that layer encodes the relevant information.\n",
    "\n",
    "**This is the key experiment**: which layer of Gemma-3 best encodes financial sentiment/return direction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train a linear probe at each layer\nprobe_results = []\n\nfor layer_idx in range(n_layers):\n    X = hidden_states[layer_idx]\n\n    # Standardize features\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n\n    # Cross-validated logistic regression\n    clf = LogisticRegression(max_iter=1000, C=1.0, random_state=42)\n    scores = cross_val_score(clf, X_scaled, labels, cv=5, scoring='accuracy')\n\n    probe_results.append({\n        \"layer\": layer_idx,\n        \"mean_accuracy\": scores.mean(),\n        \"std_accuracy\": scores.std(),\n        \"layer_type\": f\"transformer_{layer_idx}\",\n    })\n\nprobe_df = pd.DataFrame(probe_results)\nprint(\"Probing Results by Layer:\")\nprint(probe_df[[\"layer\", \"mean_accuracy\", \"std_accuracy\"]].to_string(index=False, float_format=\"%.3f\"))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. The Probing Curve\n",
    "This is the signature plot of probing analysis. It reveals WHERE in the network financial-relevant information is encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, ax = plt.subplots(figsize=(12, 6))\n\n# Plot probing accuracy by layer\nax.plot(probe_df[\"layer\"], probe_df[\"mean_accuracy\"], 'o-', color='steelblue', \n        linewidth=2, markersize=8, label=\"Probe Accuracy\")\nax.fill_between(probe_df[\"layer\"], \n                probe_df[\"mean_accuracy\"] - probe_df[\"std_accuracy\"],\n                probe_df[\"mean_accuracy\"] + probe_df[\"std_accuracy\"],\n                alpha=0.2, color='steelblue')\n\n# Reference lines\nax.axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label=\"Random Baseline (50%)\")\nbest_layer = probe_df.loc[probe_df[\"mean_accuracy\"].idxmax()]\nax.axvline(x=best_layer[\"layer\"], color='green', linestyle='--', alpha=0.5,\n           label=f\"Best Layer: {int(best_layer['layer'])} ({best_layer['mean_accuracy']:.1%})\")\n\nax.set_xlabel(\"Transformer Layer Index\", fontsize=12)\nax.set_ylabel(\"5-Fold CV Accuracy\", fontsize=12)\nax.set_title(\"Financial Sentiment Probing Curve (Gemma-3-270M)\", fontsize=14, fontweight='bold')\nax.legend(fontsize=10)\nax.set_xticks(range(n_layers))\nax.set_ylim(0.4, 1.0)\nax.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nBest probing layer: {int(best_layer['layer'])} with accuracy {best_layer['mean_accuracy']:.1%}\")\nprint(f\"Interpretation: Layer {int(best_layer['layer'])} encodes the most financial-return-relevant information\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Feature Quality Across Layers\n",
    "Use the best probing layer as the feature extractor, not the last layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compare embeddings from different layers\nlayers_to_compare = [0, n_layers // 4, n_layers // 2, 3 * n_layers // 4, n_layers - 1, int(best_layer[\"layer\"])]\nlayers_to_compare = sorted(set(layers_to_compare))\n\nfig, axes = plt.subplots(2, 3, figsize=(18, 10))\naxes = axes.flatten()\n\nfrom sklearn.decomposition import PCA\n\nfor idx, layer in enumerate(layers_to_compare[:6]):\n    pca = PCA(n_components=2)\n    X_2d = pca.fit_transform(hidden_states[layer])\n    \n    ax = axes[idx]\n    for label, color, name in [(1, 'green', 'Positive'), (0, 'red', 'Negative')]:\n        mask = labels == label\n        ax.scatter(X_2d[mask, 0], X_2d[mask, 1], c=color, label=name, alpha=0.6, s=50, edgecolors='black', linewidth=0.3)\n    \n    acc = probe_df[probe_df[\"layer\"] == layer][\"mean_accuracy\"].values[0]\n    layer_name = f\"layer {layer}\"\n    is_best = layer == int(best_layer[\"layer\"])\n    title = f\"{'\\u2605 ' if is_best else ''}Layer {layer} ({layer_name})\\nProbe acc: {acc:.1%}\"\n    ax.set_title(title, fontweight='bold' if is_best else 'normal')\n    ax.legend(fontsize=8)\n\nplt.suptitle(\"Hidden State Geometry Across Layers\", fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Using Probing Results for Feature Engineering\n",
    "\n",
    "The practical implication: **don't just use the last layer**. Use the layer where financial information is most accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Practical comparison: features from last layer vs best probing layer\nbest_l = int(best_layer[\"layer\"])\nlast_l = n_layers - 1\n\nfrom sklearn.metrics import classification_report\n\nfor layer, name in [(last_l, \"Last Layer\"), (best_l, \"Best Probing Layer\")]:\n    X = StandardScaler().fit_transform(hidden_states[layer])\n    clf = LogisticRegression(max_iter=1000, random_state=42)\n    scores = cross_val_score(clf, X, labels, cv=5, scoring='accuracy')\n    print(f\"\\n{name} (layer {layer}):\")\n    print(f\"  CV Accuracy: {scores.mean():.3f} +/- {scores.std():.3f}\")\n\nprint(f\"\\nConclusion: For feature extraction, use layer {best_l} instead of layer {last_l}\")\nprint(\"This principle applies to any LLM — always probe first, then extract features from the best layer.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Discussion & Interview Talking Points\n\n### Why This Is My Strongest Unique Contribution\n- **Nobody else at Numerai is thinking about this.** Standard practice is to use the last layer or [CLS] token. Probing reveals that this is often suboptimal.\n- **NNsight/NDIF** (my ICLR paper) makes this trivial at scale — we built infrastructure to probe ANY open-weight model without engineering overhead.\n- **nnterp** standardizes layer access across architectures: `model.layers_output[i]` works for Gemma, Llama, Mistral, etc.\n- **David Bau's lab** pioneered network dissection and representation engineering. This is my daily research.\n\n### The Research Insight\n- Early layers: capture syntax and token identity\n- Middle layers: capture semantics, entities, relationships\n- Late layers: capture task-specific features (for pre-training task, not necessarily YOUR task)\n- **For financial applications**: The best layer is likely in the middle-to-upper range, where semantic understanding peaks but pre-training task specialization hasn't yet dominated.\n\n### How I'd Apply This at Numerai\n1. **Probe first**: Before any fine-tuning, probe each layer of the target LLM for financial signal\n2. **Layer selection**: Use the best probing layer for feature extraction\n3. **Multi-layer features**: Concatenate representations from multiple informative layers\n4. **Probing as model selection**: Compare different LLMs (Llama, Mistral, FinBERT) by their probing curves — which model has the most financial signal built-in?\n5. **Probing during fine-tuning**: Track how probing accuracy changes during fine-tuning to detect overfitting\n\n### Connection to Token Entanglement (NeurIPS 2025)\nMy NeurIPS workshop paper studied how information flows between tokens. Applied to finance:\n- When a headline mentions \"Apple\" and \"antitrust\", how does the model's representation of Apple change?\n- Token entanglement analysis could reveal HOW the model processes financial relationships\n\n### Extensions (TODO)\n- [ ] Probe for more nuanced labels: return magnitude, volatility, sector\n- [ ] Compare probing curves across models: Gemma-3, Llama-3, FinBERT, SmolLM\n- [ ] Multi-layer feature concatenation (best 3 layers)\n- [ ] Causal probing: not just where, but HOW financial knowledge is encoded\n- [ ] Probing with larger datasets (1000+ headlines with real returns)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 4,
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}