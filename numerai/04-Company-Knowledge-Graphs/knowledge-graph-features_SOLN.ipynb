{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Company Knowledge Graphs from Financial Text\n",
    "\n",
    "## Context\n",
    "This is where my background maps most directly to Numerai's needs. My Cambridge University Press textbook (524 pages, 147 figures) covers spectral methods, community detection, and statistical inference on networks — all applicable to extracting graph-based features from financial text.\n",
    "\n",
    "## Why Knowledge Graphs for Numerai\n",
    "- **Highly orthogonal**: Graph topology features (centrality, clustering, community structure) are fundamentally different from Barra factors (momentum, value, size). Numerai's neutralization won't remove them.\n",
    "- **Supply chain propagation**: Shocks propagate through company networks. A supplier's bad news affects its customers — graph features capture this.\n",
    "- **Co-mention networks**: Companies mentioned together in news share latent relationships that predict correlated returns.\n",
    "\n",
    "## Pipeline\n",
    "Financial text → NER (extract company names) → Co-mention graph → Graph features per node → Stock-level predictions\n",
    "\n",
    "## Connection to My Research\n",
    "- Textbook: \"Hands-On Network Machine Learning\" (Cambridge UP, 2025) — spectral graph theory, community detection, random graph models\n",
    "- Graspologic: Co-authored open-source graph statistics library (adopted by Microsoft Research)\n",
    "- Blue Halo: Led knowledge graph effort for object detection project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from collections import defaultdict, Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sample Financial News Articles\n",
    "Each article mentions one or more companies. Co-mentions reveal relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic financial news articles with company mentions\n",
    "# In production: from Common Crawl, news APIs, or SEC filings\n",
    "articles = [\n",
    "    {\"date\": \"2024-01-15\", \"text\": \"Apple and Microsoft are leading the AI race, with both companies integrating generative AI across their product lines.\", \"source\": \"reuters\"},\n",
    "    {\"date\": \"2024-01-15\", \"text\": \"NVIDIA reported record revenue driven by demand from Microsoft Azure, Google Cloud, and Amazon Web Services.\", \"source\": \"bloomberg\"},\n",
    "    {\"date\": \"2024-01-15\", \"text\": \"Tesla and BYD are engaged in an intense price war across the Chinese electric vehicle market.\", \"source\": \"reuters\"},\n",
    "    {\"date\": \"2024-01-16\", \"text\": \"Apple's new Vision Pro headset uses chips manufactured by TSMC, continuing their long-standing partnership.\", \"source\": \"wsj\"},\n",
    "    {\"date\": \"2024-01-16\", \"text\": \"Meta and Google are competing for advertising dominance, both leveraging AI recommendation engines.\", \"source\": \"ft\"},\n",
    "    {\"date\": \"2024-01-16\", \"text\": \"Amazon and Microsoft cloud services face growing competition from Google Cloud Platform.\", \"source\": \"bloomberg\"},\n",
    "    {\"date\": \"2024-01-16\", \"text\": \"JPMorgan and Goldman Sachs both reported strong Q4 earnings, beating analyst expectations.\", \"source\": \"reuters\"},\n",
    "    {\"date\": \"2024-01-17\", \"text\": \"NVIDIA's new Blackwell GPU architecture is expected to power next-gen AI training at Google, Meta, and Microsoft data centers.\", \"source\": \"techcrunch\"},\n",
    "    {\"date\": \"2024-01-17\", \"text\": \"Intel struggles to compete with NVIDIA and AMD in the data center GPU market.\", \"source\": \"bloomberg\"},\n",
    "    {\"date\": \"2024-01-17\", \"text\": \"ExxonMobil and Chevron are both expanding their Permian Basin operations.\", \"source\": \"reuters\"},\n",
    "    {\"date\": \"2024-01-17\", \"text\": \"Apple supplier Foxconn reports strong revenue growth, suggesting robust iPhone demand.\", \"source\": \"nikkei\"},\n",
    "    {\"date\": \"2024-01-18\", \"text\": \"Samsung and TSMC are racing to develop 2nm chip manufacturing processes.\", \"source\": \"bloomberg\"},\n",
    "    {\"date\": \"2024-01-18\", \"text\": \"Pfizer and Johnson & Johnson face headwinds as post-pandemic pharmaceutical demand normalizes.\", \"source\": \"reuters\"},\n",
    "    {\"date\": \"2024-01-18\", \"text\": \"Google's antitrust case could reshape the tech landscape, impacting Apple's search deal revenue.\", \"source\": \"wsj\"},\n",
    "    {\"date\": \"2024-01-18\", \"text\": \"Tesla supplier Panasonic expands battery production capacity for the Cybertruck.\", \"source\": \"nikkei\"},\n",
    "    {\"date\": \"2024-01-19\", \"text\": \"Microsoft and OpenAI deepen their partnership with additional $10B investment.\", \"source\": \"ft\"},\n",
    "    {\"date\": \"2024-01-19\", \"text\": \"Meta launches Llama 3, challenging OpenAI and Google in the open-source AI model space.\", \"source\": \"techcrunch\"},\n",
    "    {\"date\": \"2024-01-19\", \"text\": \"Amazon's advertising business grows rapidly, eating into Google and Meta's market share.\", \"source\": \"bloomberg\"},\n",
    "    {\"date\": \"2024-01-19\", \"text\": \"Boeing faces new safety scrutiny after incidents involving its 737 MAX aircraft.\", \"source\": \"reuters\"},\n",
    "    {\"date\": \"2024-01-19\", \"text\": \"Walmart and Amazon compete for dominance in the grocery delivery space.\", \"source\": \"wsj\"},\n",
    "    {\"date\": \"2024-01-20\", \"text\": \"Apple, Google, and Samsung dominate the global smartphone market.\", \"source\": \"idc\"},\n",
    "    {\"date\": \"2024-01-20\", \"text\": \"Broadcom and NVIDIA are the biggest beneficiaries of the AI infrastructure boom.\", \"source\": \"bloomberg\"},\n",
    "    {\"date\": \"2024-01-20\", \"text\": \"JPMorgan warns that commercial real estate risks could impact Goldman Sachs and Morgan Stanley.\", \"source\": \"ft\"},\n",
    "    {\"date\": \"2024-01-20\", \"text\": \"Tesla's autonomous driving technology faces scrutiny from regulators at NHTSA.\", \"source\": \"reuters\"},\n",
    "    {\"date\": \"2024-01-20\", \"text\": \"Microsoft and Google race to integrate AI into enterprise productivity software.\", \"source\": \"techcrunch\"},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(articles)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "print(f\"Loaded {len(df)} articles spanning {df['date'].min().date()} to {df['date'].max().date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Named Entity Recognition (Company Extraction)\n",
    "In production, we'd use spaCy NER or a fine-tuned model. Here we use dictionary matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Company name -> ticker mapping (in production: use a comprehensive database)\n",
    "COMPANY_TICKERS = {\n",
    "    \"Apple\": \"AAPL\", \"Microsoft\": \"MSFT\", \"Google\": \"GOOGL\", \"Alphabet\": \"GOOGL\",\n",
    "    \"Amazon\": \"AMZN\", \"Meta\": \"META\", \"Facebook\": \"META\", \"NVIDIA\": \"NVDA\",\n",
    "    \"Tesla\": \"TSLA\", \"JPMorgan\": \"JPM\", \"Goldman Sachs\": \"GS\", \"Morgan Stanley\": \"MS\",\n",
    "    \"Intel\": \"INTL\", \"AMD\": \"AMD\", \"Samsung\": \"005930.KS\", \"TSMC\": \"TSM\",\n",
    "    \"ExxonMobil\": \"XOM\", \"Chevron\": \"CVX\", \"Pfizer\": \"PFE\",\n",
    "    \"Johnson & Johnson\": \"JNJ\", \"Boeing\": \"BA\", \"Walmart\": \"WMT\",\n",
    "    \"Foxconn\": \"2317.TW\", \"Panasonic\": \"6752.T\", \"BYD\": \"BYDDY\",\n",
    "    \"Broadcom\": \"AVGO\", \"OpenAI\": \"OPENAI\",  # private, but included for network\n",
    "}\n",
    "\n",
    "def extract_companies(text):\n",
    "    \"\"\"Extract company mentions from text using dictionary matching.\"\"\"\n",
    "    found = []\n",
    "    for company, ticker in COMPANY_TICKERS.items():\n",
    "        if company.lower() in text.lower():\n",
    "            found.append(ticker)\n",
    "    return list(set(found))  # deduplicate\n",
    "\n",
    "# Extract companies from each article\n",
    "df[\"companies\"] = df[\"text\"].apply(extract_companies)\n",
    "df[\"n_companies\"] = df[\"companies\"].apply(len)\n",
    "\n",
    "print(\"Sample extractions:\")\n",
    "for _, row in df.head(5).iterrows():\n",
    "    print(f\"  [{', '.join(row['companies'])}] {row['text'][:80]}...\")\n",
    "print(f\"\\nArticles with 2+ companies: {(df['n_companies'] >= 2).sum()}/{len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Co-Mention Graph\n",
    "Edge weight = number of articles mentioning both companies. This is the simplest network construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build co-mention graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Count co-mentions\n",
    "co_mentions = defaultdict(int)\n",
    "for _, row in df.iterrows():\n",
    "    companies = row[\"companies\"]\n",
    "    for i in range(len(companies)):\n",
    "        for j in range(i + 1, len(companies)):\n",
    "            pair = tuple(sorted([companies[i], companies[j]]))\n",
    "            co_mentions[pair] += 1\n",
    "\n",
    "# Add edges\n",
    "for (c1, c2), weight in co_mentions.items():\n",
    "    G.add_edge(c1, c2, weight=weight)\n",
    "\n",
    "# Add isolated nodes (companies mentioned but never co-mentioned)\n",
    "all_companies = set()\n",
    "for companies in df[\"companies\"]:\n",
    "    all_companies.update(companies)\n",
    "for c in all_companies:\n",
    "    if c not in G:\n",
    "        G.add_node(c)\n",
    "\n",
    "print(f\"Graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "print(f\"Density: {nx.density(G):.3f}\")\n",
    "print(f\"\\nTop co-mentions:\")\n",
    "for (c1, c2), w in sorted(co_mentions.items(), key=lambda x: -x[1])[:10]:\n",
    "    print(f\"  {c1} — {c2}: {w} articles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compute Graph Features Per Node\n",
    "These become stock-level features for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute graph features for each node\n",
    "pagerank = nx.pagerank(G, weight='weight')\n",
    "degree_cent = nx.degree_centrality(G)\n",
    "betweenness = nx.betweenness_centrality(G, weight='weight')\n",
    "closeness = nx.closeness_centrality(G)\n",
    "clustering = nx.clustering(G, weight='weight')\n",
    "\n",
    "# Weighted degree (total co-mention count)\n",
    "weighted_degree = dict(G.degree(weight='weight'))\n",
    "\n",
    "# Compile into DataFrame\n",
    "graph_features = pd.DataFrame({\n",
    "    \"ticker\": list(G.nodes()),\n",
    "    \"pagerank\": [pagerank[n] for n in G.nodes()],\n",
    "    \"degree_centrality\": [degree_cent[n] for n in G.nodes()],\n",
    "    \"betweenness_centrality\": [betweenness[n] for n in G.nodes()],\n",
    "    \"closeness_centrality\": [closeness[n] for n in G.nodes()],\n",
    "    \"clustering_coefficient\": [clustering[n] for n in G.nodes()],\n",
    "    \"weighted_degree\": [weighted_degree[n] for n in G.nodes()],\n",
    "    \"n_neighbors\": [len(list(G.neighbors(n))) for n in G.nodes()],\n",
    "}).sort_values(\"pagerank\", ascending=False)\n",
    "\n",
    "print(\"Graph Features Per Stock:\")\n",
    "print(graph_features.to_string(index=False, float_format=\"%.4f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sector mapping for coloring\n",
    "sector_map = {\n",
    "    \"AAPL\": \"Tech\", \"MSFT\": \"Tech\", \"GOOGL\": \"Tech\", \"AMZN\": \"Tech\", \"META\": \"Tech\",\n",
    "    \"NVDA\": \"Tech\", \"INTL\": \"Tech\", \"AMD\": \"Tech\", \"AVGO\": \"Tech\", \"OPENAI\": \"Tech\",\n",
    "    \"TSM\": \"Semiconductor\", \"005930.KS\": \"Semiconductor\",\n",
    "    \"TSLA\": \"Auto\", \"BYDDY\": \"Auto\",\n",
    "    \"JPM\": \"Finance\", \"GS\": \"Finance\", \"MS\": \"Finance\",\n",
    "    \"XOM\": \"Energy\", \"CVX\": \"Energy\",\n",
    "    \"PFE\": \"Healthcare\", \"JNJ\": \"Healthcare\",\n",
    "    \"BA\": \"Industrial\", \"WMT\": \"Retail\",\n",
    "    \"2317.TW\": \"Manufacturing\", \"6752.T\": \"Manufacturing\",\n",
    "}\n",
    "sector_colors = {\n",
    "    \"Tech\": \"#4285F4\", \"Semiconductor\": \"#34A853\", \"Auto\": \"#EA4335\",\n",
    "    \"Finance\": \"#FBBC04\", \"Energy\": \"#FF6D01\", \"Healthcare\": \"#46BDC6\",\n",
    "    \"Industrial\": \"#7B1FA2\", \"Retail\": \"#E91E63\", \"Manufacturing\": \"#795548\",\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "pos = nx.spring_layout(G, k=2, seed=42, weight='weight')\n",
    "\n",
    "# Node sizes proportional to PageRank\n",
    "node_sizes = [pagerank[n] * 15000 + 200 for n in G.nodes()]\n",
    "node_colors = [sector_colors.get(sector_map.get(n, \"Tech\"), \"#999999\") for n in G.nodes()]\n",
    "\n",
    "# Edge widths proportional to weight\n",
    "edge_weights = [G[u][v]['weight'] for u, v in G.edges()]\n",
    "max_weight = max(edge_weights) if edge_weights else 1\n",
    "\n",
    "# Draw\n",
    "nx.draw_networkx_edges(G, pos, width=[w / max_weight * 4 for w in edge_weights], \n",
    "                       alpha=0.3, edge_color='gray', ax=ax)\n",
    "nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors,\n",
    "                       edgecolors='black', linewidths=0.5, alpha=0.8, ax=ax)\n",
    "nx.draw_networkx_labels(G, pos, font_size=8, font_weight='bold', ax=ax)\n",
    "\n",
    "# Legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=c, label=s) for s, c in sector_colors.items() if any(sector_map.get(n) == s for n in G.nodes())]\n",
    "ax.legend(handles=legend_elements, loc='upper left', fontsize=9)\n",
    "ax.set_title(\"Company Co-Mention Network from Financial News\", fontsize=14, fontweight='bold')\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Community Detection\n",
    "Identifying clusters of companies that are discussed together reveals latent industry relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Community detection\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "\n",
    "communities = list(greedy_modularity_communities(G, weight='weight'))\n",
    "print(f\"Detected {len(communities)} communities:\\n\")\n",
    "for i, comm in enumerate(communities):\n",
    "    sectors = [sector_map.get(n, \"?\") for n in comm]\n",
    "    print(f\"  Community {i}: {sorted(comm)}\")\n",
    "    print(f\"    Sectors: {Counter(sectors).most_common()}\\n\")\n",
    "\n",
    "# Add community assignment as a feature\n",
    "community_map = {}\n",
    "for i, comm in enumerate(communities):\n",
    "    for node in comm:\n",
    "        community_map[node] = i\n",
    "\n",
    "graph_features[\"community\"] = graph_features[\"ticker\"].map(community_map)\n",
    "\n",
    "# Visualize communities\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "community_colors = plt.cm.Set3(np.linspace(0, 1, len(communities)))\n",
    "node_colors_comm = [community_colors[community_map.get(n, 0)] for n in G.nodes()]\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, width=[w / max_weight * 4 for w in edge_weights],\n",
    "                       alpha=0.3, edge_color='gray', ax=ax)\n",
    "nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors_comm,\n",
    "                       edgecolors='black', linewidths=1, alpha=0.8, ax=ax)\n",
    "nx.draw_networkx_labels(G, pos, font_size=8, font_weight='bold', ax=ax)\n",
    "ax.set_title(\"Community Structure in Co-Mention Network\", fontsize=14, fontweight='bold')\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Dynamic Network Features (Temporal Evolution)\n",
    "Track how a company's network position changes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split articles by date and build time-windowed graphs\n",
    "dates = sorted(df[\"date\"].unique())\n",
    "mid = len(dates) // 2\n",
    "window1 = df[df[\"date\"] <= dates[mid]]\n",
    "window2 = df[df[\"date\"] > dates[mid]]\n",
    "\n",
    "def build_graph(articles_df):\n",
    "    g = nx.Graph()\n",
    "    co_m = defaultdict(int)\n",
    "    for _, row in articles_df.iterrows():\n",
    "        companies = row[\"companies\"]\n",
    "        for i in range(len(companies)):\n",
    "            for j in range(i + 1, len(companies)):\n",
    "                pair = tuple(sorted([companies[i], companies[j]]))\n",
    "                co_m[pair] += 1\n",
    "    for (c1, c2), w in co_m.items():\n",
    "        g.add_edge(c1, c2, weight=w)\n",
    "    return g\n",
    "\n",
    "G1 = build_graph(window1)\n",
    "G2 = build_graph(window2)\n",
    "\n",
    "# Compare PageRank across windows\n",
    "pr1 = nx.pagerank(G1, weight='weight')\n",
    "pr2 = nx.pagerank(G2, weight='weight')\n",
    "\n",
    "# Compute delta\n",
    "all_nodes = sorted(set(list(pr1.keys()) + list(pr2.keys())))\n",
    "delta_pr = {n: pr2.get(n, 0) - pr1.get(n, 0) for n in all_nodes}\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Top movers\n",
    "sorted_delta = sorted(delta_pr.items(), key=lambda x: abs(x[1]), reverse=True)[:15]\n",
    "tickers = [x[0] for x in sorted_delta]\n",
    "deltas = [x[1] for x in sorted_delta]\n",
    "colors = ['green' if d > 0 else 'red' for d in deltas]\n",
    "\n",
    "axes[0].barh(tickers[::-1], deltas[::-1], color=colors[::-1], edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(x=0, color='black', linewidth=0.5)\n",
    "axes[0].set_xlabel(\"PageRank Change\")\n",
    "axes[0].set_title(f\"PageRank Change: Window 1 -> Window 2\")\n",
    "\n",
    "# Side-by-side PageRank\n",
    "top_nodes = sorted(pr1.keys(), key=lambda x: pr1.get(x, 0) + pr2.get(x, 0), reverse=True)[:12]\n",
    "x = np.arange(len(top_nodes))\n",
    "width = 0.35\n",
    "axes[1].bar(x - width/2, [pr1.get(n, 0) for n in top_nodes], width, label=\"Window 1\", color=\"steelblue\")\n",
    "axes[1].bar(x + width/2, [pr2.get(n, 0) for n in top_nodes], width, label=\"Window 2\", color=\"coral\")\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(top_nodes, rotation=45, ha='right')\n",
    "axes[1].set_ylabel(\"PageRank\")\n",
    "axes[1].set_title(\"PageRank by Time Window\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.suptitle(\"Dynamic Network Features: How Company Importance Evolves\", fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Spectral Features (From My Textbook)\n",
    "\n",
    "The eigenvalues of the graph Laplacian encode global network structure. The Fiedler vector (2nd smallest eigenvalue) reveals the fundamental partition of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral analysis of the co-mention graph\n",
    "L = nx.laplacian_matrix(G).toarray().astype(float)\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(L)\n",
    "\n",
    "# Fiedler vector (2nd eigenvector) — reveals fundamental graph partition\n",
    "fiedler = eigenvectors[:, 1]\n",
    "nodes = list(G.nodes())\n",
    "\n",
    "# Plot spectrum\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(eigenvalues[:15], 'o-', color='steelblue', markersize=8)\n",
    "axes[0].set_xlabel(\"Index\")\n",
    "axes[0].set_ylabel(\"Eigenvalue\")\n",
    "axes[0].set_title(\"Graph Laplacian Spectrum (first 15)\")\n",
    "axes[0].axhline(y=0, color='gray', linestyle='--', alpha=0.3)\n",
    "\n",
    "# Fiedler vector values per node\n",
    "sorted_idx = np.argsort(fiedler)\n",
    "axes[1].barh([nodes[i] for i in sorted_idx], fiedler[sorted_idx],\n",
    "             color=['steelblue' if f > 0 else 'coral' for f in fiedler[sorted_idx]],\n",
    "             edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(x=0, color='black', linewidth=0.5)\n",
    "axes[1].set_xlabel(\"Fiedler Vector Value\")\n",
    "axes[1].set_title(\"Spectral Partition (Fiedler Vector)\")\n",
    "\n",
    "plt.suptitle(\"Spectral Graph Features from Co-Mention Network\", fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Add spectral features\n",
    "spectral_features = pd.DataFrame({\n",
    "    \"ticker\": nodes,\n",
    "    \"fiedler_value\": fiedler,\n",
    "    \"spectral_partition\": (fiedler > 0).astype(int),\n",
    "})\n",
    "print(\"Spectral features:\")\n",
    "print(spectral_features.sort_values(\"fiedler_value\").to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion & Interview Talking Points\n",
    "\n",
    "### Why This Is My Strongest Angle for Numerai\n",
    "- **My textbook**: 524-page Cambridge University Press book on network ML — I wrote the chapter on spectral methods\n",
    "- **Graspologic**: Co-authored open-source graph statistics library (adopted by Microsoft Research)\n",
    "- **Blue Halo**: Led knowledge graph effort for a defense project — same entity extraction -> graph -> features pipeline\n",
    "\n",
    "### Feature Summary for Numerai Signals\n",
    "Per-stock graph features (all per time window):\n",
    "| Feature | What It Captures | Orthogonality |\n",
    "|---------|-----------------|---------------|\n",
    "| PageRank | Overall importance in news network | High |\n",
    "| Betweenness Centrality | Bridges between industry clusters | Very High |\n",
    "| Clustering Coefficient | How tightly connected a company's neighbors are | High |\n",
    "| Community Assignment | Latent industry grouping from news (not standard GICS) | Very High |\n",
    "| Fiedler Value | Position in spectral partition | Very High |\n",
    "| Delta PageRank | Change in network importance over time | Very High |\n",
    "\n",
    "### Why These Features Are Orthogonal\n",
    "- **Barra factors** (momentum, value, size) operate on single-stock time series\n",
    "- **Graph features** operate on inter-stock relationships derived from text\n",
    "- These are structurally different — neutralization shouldn't remove them\n",
    "- \"Supply chain shocks propagate through networks — my graph features capture this propagation before it shows up in returns\"\n",
    "\n",
    "### Extensions (TODO)\n",
    "- [ ] Use spaCy NER instead of dictionary matching for entity extraction\n",
    "- [ ] Build directed graphs (company A mentioned as supplier OF company B)\n",
    "- [ ] Add edge sentiment (positive vs negative co-mention)\n",
    "- [ ] Adjacency spectral embedding (Chapter 5 of my textbook)\n",
    "- [ ] Test on real news data from GDELT or Tiingo API\n",
    "- [ ] Dynamic stochastic block model for evolving communities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 2,
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}